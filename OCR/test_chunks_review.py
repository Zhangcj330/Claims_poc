#!/usr/bin/env python3
"""
OCR Chunks Review - å¿«é€Ÿæµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºå¿«é€Ÿæµ‹è¯• chunks reviewer ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œ
æ— éœ€æ¶ˆè€—å¤§é‡ API è°ƒç”¨ã€‚
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_environment():
    """æµ‹è¯•ç¯å¢ƒé…ç½®"""
    print("ğŸ§ª æµ‹è¯•ç¯å¢ƒé…ç½®...")
    
    # æ£€æŸ¥ .env æ–‡ä»¶
    load_dotenv()
    
    if not os.getenv('GOOGLE_API_KEY'):
        print("âŒ ç¼ºå°‘ GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶è®¾ç½® API key")
        return False
    else:
        api_key = os.getenv('GOOGLE_API_KEY')
        print(f"âœ… API Key å·²è®¾ç½® ({api_key[:10]}...)")
    
    return True

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…"""
    print("\nğŸ§ª æµ‹è¯•ä¾èµ–åŒ…...")
    
    required_packages = [
        'fitz',  # PyMuPDF
        'PIL',   # Pillow
        'langchain_google_genai',
        'dotenv'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            if package == 'fitz':
                import fitz
            elif package == 'PIL':
                from PIL import Image
            elif package == 'langchain_google_genai':
                from langchain_google_genai import ChatGoogleGenerativeAI
            elif package == 'dotenv':
                from dotenv import load_dotenv
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package}")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("ğŸ’¡ è¯·è¿è¡Œ: pip install python-dotenv langchain-google-genai PyMuPDF Pillow")
        return False
    
    return True

def test_files():
    """æµ‹è¯•è¾“å…¥æ–‡ä»¶"""
    print("\nğŸ§ª æµ‹è¯•è¾“å…¥æ–‡ä»¶...")
    
    test_files = [
        "Data_Json/TAL_AcceleratedProtection_2022-08-05_chunks.jsonl",
        "TAL_AcceleratedProtection_2022-08-05.pdf"
    ]
    
    all_exist = True
    for file_path in test_files:
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"âœ… {file_path} ({size:,} bytes)")
        else:
            print(f"âŒ {file_path} (ä¸å­˜åœ¨)")
            all_exist = False
    
    if not all_exist:
        print("\nğŸ’¡ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†ç³»ç»Ÿä»å¯ä½¿ç”¨å…¶ä»–æ–‡ä»¶")
    
    return True

def test_system_initialization():
    """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
    print("\nğŸ§ª æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–...")
    
    try:
        from chunks_reviewer import ChunksReviewer
        reviewer = ChunksReviewer()
        print("âœ… ChunksReviewer åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_file_loading():
    """æµ‹è¯•æ–‡ä»¶åŠ è½½åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ–‡ä»¶åŠ è½½åŠŸèƒ½...")
    
    jsonl_file = "Data_Json/TAL_AcceleratedProtection_2022-08-05_chunks.jsonl"
    
    if not os.path.exists(jsonl_file):
        print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {jsonl_file}")
        return True
    
    try:
        from chunks_reviewer import ChunksReviewer
        reviewer = ChunksReviewer()
        
        # æµ‹è¯•åŠ è½½ chunks
        chunks = reviewer.load_chunks_from_jsonl(jsonl_file)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(chunks)} ä¸ª chunks")
        
        # æµ‹è¯•åˆ†ç»„
        page_groups = reviewer.group_chunks_by_page(chunks)
        print(f"âœ… æˆåŠŸåˆ†ç»„åˆ° {len(page_groups)} ä¸ªé¡µé¢")
        
        # æµ‹è¯•å…ƒæ•°æ®æå–
        metadata = reviewer.extract_global_metadata(chunks)
        print(f"âœ… æˆåŠŸæå–å…ƒæ•°æ®: {metadata.get('Insurer', 'Unknown')}")
        
        return True
    except Exception as e:
        print(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def test_pdf_processing():
    """æµ‹è¯• PDF å¤„ç†åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯• PDF å¤„ç†åŠŸèƒ½...")
    
    pdf_file = "TAL_AcceleratedProtection_2022-08-05.pdf"
    
    if not os.path.exists(pdf_file):
        print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
        return True
    
    try:
        from chunks_reviewer import ChunksReviewer
        reviewer = ChunksReviewer()
        
        # æµ‹è¯•é¡µé¢è½¬å›¾åƒ
        page_image = reviewer.pdf_page_to_image(pdf_file, page_no=1)
        if page_image:
            print(f"âœ… PDF é¡µé¢è½¬å›¾åƒæˆåŠŸ: {page_image.size}")
            
            # æµ‹è¯•å›¾åƒç¼–ç 
            encoded = reviewer.encode_image(page_image)
            print(f"âœ… å›¾åƒç¼–ç æˆåŠŸ: {len(encoded)} characters")
        else:
            print("âŒ PDF é¡µé¢è½¬å›¾åƒå¤±è´¥")
            return False
        
        return True
    except Exception as e:
        print(f"âŒ PDF å¤„ç†å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ OCR Chunks Review System - å¿«é€Ÿæµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("ç¯å¢ƒé…ç½®", test_environment),
        ("ä¾èµ–åŒ…", test_dependencies), 
        ("è¾“å…¥æ–‡ä»¶", test_files),
        ("ç³»ç»Ÿåˆå§‹åŒ–", test_system_initialization),
        ("æ–‡ä»¶åŠ è½½", test_file_loading),
        ("PDFå¤„ç†", test_pdf_processing)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. è¿è¡Œ: python run_chunks_review.py --dry-run")
        print("   2. æˆ–ä½¿ç”¨: python run_chunks_review.py")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè§£å†³é—®é¢˜")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 